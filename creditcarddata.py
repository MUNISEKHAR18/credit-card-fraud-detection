# -*- coding: utf-8 -*-
"""creditcarddata.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dOtoMeKKQpC3D7ZVb0HDotGAcbpqGwq3
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

cc_data = pd.read_csv('/content/creditcard.csv', error_bad_lines=False)

cc_data.head()

cc_data.tail()

cc_data.info()

cc_data.isnull().sum()

cc_data.fillna(0, inplace=True)

cc_data.isnull().sum()

cc_data['Class'].value_counts()

"""0=represent normal transaction
1=represent fraudulent transaction
"""

legit=cc_data[cc_data.Class==0]
fraud=cc_data[cc_data.Class==1]

legit.Amount.describe() #giving the informaction of amount

print(legit.shape)
print(fraud.shape)

fraud.Amount.describe()

cc_data.groupby('Class').mean()

#taking the under smapling data
#number of fraudulent transction =425
legit_sample=legit.sample(n=425)

new_dataset=pd.concat([legit_sample,fraud],axis=0)

new_dataset.head()#check the data the it will take random values

new_dataset['Class'].value_counts() #you can see the both data set is same now

new_dataset.groupby('Class').mean()

#now we need to splite the data into features and target
a=new_dataset.drop(columns='Class',axis=1)
b=new_dataset['Class']
print(a)
print(b)

a_train,a_test,b_train,b_test=train_test_split(a,b,test_size=0.2,stratify=b, random_state=2)

print(a.shape,a_train.shape,a_test.shape)

#logistic regression
sets=LogisticRegression()

#we need to train the sets with training data
sets.fit(a_train,b_train)

#performance of over model or sets
#by checking the accuracy score
a_train_prediction=sets.predict(a_train)
training_data_accuracy=accuracy_score(a_train_prediction,b_train)

print('accurancy on Training data:',training_data_accuracy)

a_test_prediction=sets.predict(a_test)
test_data_accuracy=accuracy_score(a_test_prediction,b_test)
print(test_data_accuracy)

